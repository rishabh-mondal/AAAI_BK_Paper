{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-03 23:12:43.251831: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-03 23:12:43.301496: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-03 23:12:44.025196: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import torch\n",
    "from utils1 import * \n",
    "import h5py\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from matplotlib.pyplot import savefig\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgs_input_fn(images):\n",
    "    img_size = (224, 224, 3)\n",
    "    images = tf.convert_to_tensor(value = images)\n",
    "    images = tf.image.resize(images, size=img_size[:2])\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hdf5_data(file_path):\n",
    "    with h5py.File(file_path, 'r') as h5_file:\n",
    "        images = np.array(h5_file['image'])\n",
    "        labels = np.array(h5_file['label'])    \n",
    "    print(\"Images shape: \", images.shape, 'Images dtype: ', images.dtype)\n",
    "    print(\"Labels shape: \", labels.shape, 'Labels dtype: ', labels.dtype)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tts_india():\n",
    "    file_path = '/home/rishabh.mondal/delhi_NCR (1).h5' # replace with the path to the dataset\n",
    "    \n",
    "    X_train, Y_train = load_hdf5_data(file_path)\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.2, stratify=Y_train, random_state=0)\n",
    "    X_train, X_pool, Y_train, Y_pool = train_test_split(X_train, Y_train, test_size=0.99, stratify = Y_train, random_state=0)\n",
    "  \n",
    "    X_train = np.array(imgs_input_fn(X_train))\n",
    "    X_pool = np.array(imgs_input_fn(X_pool))\n",
    "    X_test = np.array(imgs_input_fn(X_test))\n",
    "\n",
    "    return X_train, X_pool, X_test, Y_train, Y_pool, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/rishabh.mondal/delhi_NCR (1).h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Define the H5 file path\n",
    "file_path = '/home/rishabh.mondal/delhi_NCR (1).h5'\n",
    "\n",
    "# Open the H5 file for reading\n",
    "with h5py.File(file_path, 'r') as file:\n",
    "    # Assuming the image data is stored in a dataset named 'image_data'\n",
    "    if 'image_data' in file:\n",
    "        image_data = file['image_data'][:]\n",
    "        # Convert the image data (assuming it's a NumPy array) to an image\n",
    "        image = Image.fromarray(image_data)\n",
    "\n",
    "        # Save the image as a PNG file (you can change the format if needed)\n",
    "        image.save('/home/rishabh.mondal/output_image.png')\n",
    "\n",
    "# Replace '/path/to/output_image.png' with the desired output file path and format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to open object (object 'label' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/rishabh.mondal/AAAI_BK_Paper-16/detection_through_torch/experiment_on_ind.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/AAAI_BK_Paper-16/detection_through_torch/experiment_on_ind.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#shape of X_train, X_pool, X_test: (no. of images, 3, 224, 224)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/AAAI_BK_Paper-16/detection_through_torch/experiment_on_ind.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#shape of Y_train, Y_pool, Y_test: (no. of images,)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/AAAI_BK_Paper-16/detection_through_torch/experiment_on_ind.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m X_train, X_pool, X_test, Y_train, Y_pool, Y_test \u001b[39m=\u001b[39m tts_india()\n",
      "\u001b[1;32m/home/rishabh.mondal/AAAI_BK_Paper-16/detection_through_torch/experiment_on_ind.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/AAAI_BK_Paper-16/detection_through_torch/experiment_on_ind.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtts_india\u001b[39m():\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/AAAI_BK_Paper-16/detection_through_torch/experiment_on_ind.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     file_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/home/rishabh.mondal/delhi_NCR (1).h5\u001b[39m\u001b[39m'\u001b[39m \u001b[39m# replace with the path to the dataset\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/AAAI_BK_Paper-16/detection_through_torch/experiment_on_ind.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     X_train, Y_train \u001b[39m=\u001b[39m load_hdf5_data(file_path)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/AAAI_BK_Paper-16/detection_through_torch/experiment_on_ind.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     X_train, X_test, Y_train, Y_test \u001b[39m=\u001b[39m train_test_split(X_train, Y_train, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, stratify\u001b[39m=\u001b[39mY_train, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/AAAI_BK_Paper-16/detection_through_torch/experiment_on_ind.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     X_train, X_pool, Y_train, Y_pool \u001b[39m=\u001b[39m train_test_split(X_train, Y_train, test_size\u001b[39m=\u001b[39m\u001b[39m0.99\u001b[39m, stratify \u001b[39m=\u001b[39m Y_train, random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;32m/home/rishabh.mondal/AAAI_BK_Paper-16/detection_through_torch/experiment_on_ind.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/AAAI_BK_Paper-16/detection_through_torch/experiment_on_ind.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwith\u001b[39;00m h5py\u001b[39m.\u001b[39mFile(file_path, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m h5_file:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/AAAI_BK_Paper-16/detection_through_torch/experiment_on_ind.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     images \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(h5_file[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/AAAI_BK_Paper-16/detection_through_torch/experiment_on_ind.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(h5_file[\u001b[39m'\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m'\u001b[39;49m])    \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/AAAI_BK_Paper-16/detection_through_torch/experiment_on_ind.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mImages shape: \u001b[39m\u001b[39m\"\u001b[39m, images\u001b[39m.\u001b[39mshape, \u001b[39m'\u001b[39m\u001b[39mImages dtype: \u001b[39m\u001b[39m'\u001b[39m, images\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.0.62.206/home/rishabh.mondal/AAAI_BK_Paper-16/detection_through_torch/experiment_on_ind.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLabels shape: \u001b[39m\u001b[39m\"\u001b[39m, labels\u001b[39m.\u001b[39mshape, \u001b[39m'\u001b[39m\u001b[39mLabels dtype: \u001b[39m\u001b[39m'\u001b[39m, labels\u001b[39m.\u001b[39mdtype)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_env/lib/python3.11/site-packages/h5py/_hl/group.py:357\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid HDF5 object reference\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    356\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(name, (\u001b[39mbytes\u001b[39m, \u001b[39mstr\u001b[39m)):\n\u001b[0;32m--> 357\u001b[0m     oid \u001b[39m=\u001b[39m h5o\u001b[39m.\u001b[39;49mopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mid, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_e(name), lapl\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lapl)\n\u001b[1;32m    358\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAccessing a group is done with bytes or str, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    360\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mnot \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(name)))\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5o.pyx:190\u001b[0m, in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unable to open object (object 'label' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "#shape of X_train, X_pool, X_test: (no. of images, 3, 224, 224)\n",
    "#shape of Y_train, Y_pool, Y_test: (no. of images,)\n",
    "X_train, X_pool, X_test, Y_train, Y_pool, Y_test = tts_india()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
